{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 56.65it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 210.51it/s]\n",
      "100%|██████████| 918/918 [00:02<00:00, 374.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd ## biblioteca de estruturação e analise de dados\n",
    "import numpy as np ## biblioteca de algebra linear entre outras utilidades\n",
    "\n",
    "import random ## biblioteca de geracao de numeros aleatorios\n",
    "import datetime ## biblioteca para criar/trabalhar datas\n",
    "\n",
    "from tqdm import tqdm ## loading bar\n",
    "\n",
    "'''\n",
    "Do enunciado:\n",
    "\n",
    "\"Todas as informações de vendas, \n",
    "tais como o valor da venda e qual empresa efetuou a compra,\n",
    "estão armazenadas em um banco de dados PostgreSQL.\"\n",
    "\n",
    "Para poder simular uma analise simples, iremos gerar dados aleatorios.\n",
    "A arquitetura do banco é simplificada ao maximo, \n",
    "a uma unica entidade composta apenas de 3 atributos.\n",
    "\n",
    "Essa arquitetura nao corresponde a uma esquematica ideal, \n",
    "é apenas uma simplificacao para fazer uma poc do exercicio.\n",
    "\n",
    "Um banco ideal deveria contemplar mais informacoes sobre as vendas,\n",
    "como informacao de cada produto, preço individual, possiveis descontos/promocoes,\n",
    "e outras informacoes pertinentes. O mesmo deveria estar devidamente normalizado,\n",
    "de maneira a conter diversas tabelas, que poderiam ser exportadas em arquivos csv\n",
    "separados, ou ainda, \"merged\" em uma unica tabela com as informacoes relevantes\n",
    "para a analise.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "O equivalente é valido para o caso dos dados do hubspot.\n",
    "\n",
    "'''\n",
    "\n",
    "## definindo sementes para replicabilidade\n",
    "random.seed(2005) \n",
    "np.random.seed(2005)\n",
    "\n",
    "##-------------------------------------------------------------##\n",
    "## criando o primeiro arquivo csv proveniente do banco postgresql\n",
    "##-------------------------------------------------------------##\n",
    "\n",
    "df = pd.DataFrame([], columns=['id_venda','cnpj','data','valor']) ## criando dataframe em branco\n",
    "\n",
    "min_date = pd.to_datetime('2017-01-01').date() ## definindo data minima, iremos contemplar apenas o ano de 2017\n",
    "\n",
    "doy_today = datetime.datetime.now().date().timetuple().tm_yday\n",
    "\n",
    "id_venda = 0\n",
    "\n",
    "for i in tqdm(np.arange(1,101,1)): ## gerando 100 entradas unicas de empresas\n",
    "    \n",
    "    number_of_purchases = random.randint(1,20) ## definindo um numero aleatorio de compras que a empresa efetuou\n",
    "    \n",
    "    cnpj = random.randint(1*10**14, 9*10**14) ## definindo o cnpj ficticio da empresa\n",
    "    \n",
    "    for j in np.arange(number_of_purchases): ## para cada compra, definindo seu valor e data\n",
    "        \n",
    "        value = random.uniform(10,200)\n",
    "        \n",
    "        date = (min_date + datetime.timedelta(days=random.randint(0,doy_today-1)))\n",
    "        \n",
    "        df.loc[len(df)] = [id_venda, cnpj, date, value] ## anexando a informacao ao dataframe\n",
    "        \n",
    "        id_venda = id_venda + 1\n",
    "\n",
    "##------------------------------------------------------------##\n",
    "## criando o segundo arquivo csv, proveniente do serviço HubSpot\n",
    "##------------------------------------------------------------##\n",
    "\n",
    "cnpjs = df.cnpj.unique() ## salvando os cnpjs das empresas\n",
    "id_representantes = np.random.randint(100,1000,25) ## gerando até 25 representantes diferentes\n",
    "\n",
    "df2 = pd.DataFrame([], columns=['cnpj','id_representante','id_contrato','data_inicio']) ## criando dataframe em branco\n",
    "\n",
    "\n",
    "for cnpj in tqdm(cnpjs): ## percorrendo as empresas\n",
    "    \n",
    "    representante = random.choice(id_representantes) ## escolhendo um representante para aquela empresa\n",
    "    \n",
    "    number_contracts = np.random.randint(1,4) ## definindo qtos contratos aquele representante fechou (1-3)\n",
    "    \n",
    "    temp_df = df.loc[df.cnpj==cnpj] ## fazendo um dataframe dummy para apenas aquela empresa\n",
    "    \n",
    "    for contract in np.arange(number_contracts): ## percorrendo os contratos\n",
    "    \n",
    "        if str(contract).endswith('0'): ## se for o primeiro, cria uma data anterior a primeira compra\n",
    "    \n",
    "            contract_id = str(representante)+'_'+str(contract)\n",
    "\n",
    "            max_date = np.min(temp_df.data)\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                date = max_date - datetime.timedelta(days=np.random.randint(0,(max_date.timetuple().tm_yday-1)))\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                date = max_date\n",
    "            \n",
    "        else: ## caso contrario, cria uma data posterior a primeira compra\n",
    "            \n",
    "            contract_id = str(representante)+'_'+str(contract)\n",
    "\n",
    "            min_date = np.min(temp_df.data)\n",
    "            \n",
    "            date = min_date + datetime.timedelta(days=np.random.randint(0, doy_today-min_date.timetuple().tm_yday))\n",
    "            \n",
    "        df2.loc[len(df2)] = [cnpj, representante, contract_id, date] # armazena os dados\n",
    "\n",
    "##------------------------------------------------------##\n",
    "## criando um terceiro df, para relacionar os 2 anteriores\n",
    "##------------------------------------------------------##\n",
    "\n",
    "df3 = pd.DataFrame([], columns=['id_contrato','id_venda'])\n",
    "\n",
    "for index in tqdm(df.index):\n",
    "    \n",
    "    dummy = df.loc[index]\n",
    "    \n",
    "    id_venda = dummy.id_venda\n",
    "    data = dummy['data']\n",
    "    cnpj = dummy.cnpj\n",
    "    \n",
    "    dummy_2 = df2.loc[(df2.cnpj==cnpj)&(df2.data_inicio<=data)]\n",
    "    \n",
    "    ids_contrato = dummy_2.id_contrato.get_values()\n",
    "    id_contrato = np.random.choice(ids_contrato)\n",
    "    \n",
    "    df3.loc[len(df3)] = [id_contrato, id_venda]\n",
    "    \n",
    "df = pd.merge(df,df3)\n",
    "\n",
    "df.to_csv('UauOffice_Vendas.csv', index=False, encoding='latin-1') ## salvando o dataset gerado\n",
    "df2.to_csv('hubspot_Vendas.csv', index=False, encoding='latin-1') ## salvando o dataset gerado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
